{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-780240de4924>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatcher\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMatcher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mspacy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "import numpy as np\n",
    "from spacy import displacy                                                 \n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spacy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-16be08557b4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Loads NLP English model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'spacy' is not defined"
     ]
    }
   ],
   "source": [
    "# Loads NLP English model\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads text\n",
    "file = open('random_full.txt','r')\n",
    "text = file.read()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text into NLP object\n",
    "textdoc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Named Entity Recognition\n",
    "#displacy.serve(doc, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = list(str(sent) for sent in list(textdoc.sents))\n",
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all sentences in the dataframe\n",
    "sentsdf = pd.DataFrame(sents, columns = ['Sentence'])\n",
    "sentsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing keywords\n",
    "general_numerical_keywords = ['time','number*','ratio','proportion','period','Â±','total*','estimate*','%']\n",
    "specific_numerical_keywords = ['infections','death*','transmis*','laten*','contact','infectious','incubat*','casualties','mortal*','morbid*','outbreak*']\n",
    "contextual_keywords = ['GPE','DATE','TIME','PRODUCT']\n",
    "\n",
    "# Creating a regular expression using keywords for searching and filtering \n",
    "trait_keywords = general_numerical_keywords + specific_numerical_keywords\n",
    "trait_keywords_regex = '|'.join(trait_keywords)\n",
    "trait_keywords_regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Parses a sentence, looking for trait-related keywords.\n",
    "\n",
    "args: sentence - string of sentence.\n",
    "return: trait_keyword_match_count - the number how many trait-related keywords the sentence contains.\n",
    "'''\n",
    "def countTraitKeywords(sentence):\n",
    "    sentence_obj = nlp(sentence)\n",
    "    trait_keyword_match_count = len(re.findall(trait_keywords_regex, str(sentence_obj)))\n",
    "    return trait_keyword_match_count\n",
    "\n",
    "'''\n",
    "Parses a sentence, looking for context-related keywords.\n",
    "\n",
    "args: sentence - string of sentence.\n",
    "return: trait_keyword_match_count - the number how many context-related keywords the sentence contains.\n",
    "'''\n",
    "def countContextualKeywords(sentence):\n",
    "    sentence_obj = nlp(sentence)\n",
    "    ent_labels = [ent.label_ for ent in sentence_obj.ents]\n",
    "    contextual_keyword_match_count = len([label for label in ent_labels if label in contextual_keywords])\n",
    "    return contextual_keyword_match_count\n",
    "\n",
    "'''\n",
    "Parses a sentence, counting occurences of cardinal elements.\n",
    "\n",
    "args: sentence - string of sentence.\n",
    "return: numericness - how many numbers the sentence contains.\n",
    "'''\n",
    "def findCardinality(sentence):\n",
    "    sentence_obj = nlp(sentence)\n",
    "    ent_labels = [ent.label_ for ent in sentence_obj.ents]\n",
    "    cardinality = len([label for label in ent_labels if label == 'CARDINAL'])\n",
    "    return cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentsdf['TKMC'] = sentsdf.Sentence.map(countTraitKeywords)\n",
    "sentsdf['CKMC'] = sentsdf.Sentence.map(countContextualKeywords)\n",
    "sentsdf['SKMC'] = sentsdf['TKMC'] + sentsdf['CKMC']\n",
    "sentsdf['Cardinality'] = sentsdf.Sentence.map(findCardinality)\n",
    "\n",
    "# My attempt at guessing how many 'numeric' each sentence is\n",
    "sentsdf['Numericness'] = sentsdf.TKMC * sentsdf.Cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example of filtering\n",
    "sentsdf_filt = sentsdf.loc[(sentsdf.SKMC >= 3) & (sentsdf.Cardinality >=2)]\n",
    "print(len(sentsdf_filt))\n",
    "sentsdf_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentences with most relevance\n",
    "sentsdf_top = sentsdf.sort_values(by=['TKMC'],ascending=False)\n",
    "sentsdf_top.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Displays the text surrounding the sentence with the provided index. To refer to the context, perhaps.\n",
    "args: idx - index of sentence in question.\n",
    "    df = Dataframe, default is sentsdf.\n",
    "    pm = plus or minus for the indices of surrounding sentences.\n",
    "'''\n",
    "def displaySurroundingText(idx, df = sentsdf, pm = 1):\n",
    "    n = len(df)\n",
    "    if (idx-pm) < 0 and (idx+pm) > n:\n",
    "        display(df)\n",
    "        return\n",
    "    elif (idx-pm) < 0:\n",
    "        display(df.loc[0:idx+pm,:])\n",
    "        return\n",
    "    elif (idx-pm) > n:\n",
    "        display(df.loc[idx-pm:n,:])\n",
    "        return\n",
    "    display(df.loc[idx-pm:idx+pm,:])\n",
    "    return\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "'''\n",
    "Print entity labels and their occurences within a given sentence.\n",
    "args: sentence - The sentence in question.\n",
    "    from_keywords - Whether or not to only include info on labels in the contextual keywords. Does not by default.\n",
    "return: list containing tuples of entity labels and their occurences.\n",
    "'''\n",
    "def printEntityLabels(sentence, from_keywords = False):\n",
    "    sentence_obj = nlp(sentence)\n",
    "    ent_labels = [ent.label_ for ent in sentence_obj.ents if (not from_keywords or ent.label_ in contextual_keywords)]\n",
    "    labels = Counter(ent_labels).keys()\n",
    "    counts = Counter(ent_labels).values()\n",
    "    return list(zip(labels, counts))\n",
    "\n",
    "'''\n",
    "Prints all sentences from Dataframe with provided keywords.\n",
    "args: filter_words: Words to filter results by. By default, the trait keywords.\n",
    "    df - The Dataframe to filter. By default, sentsdf.\n",
    "return: Returns Dataframe with only sentences including keywords from the list.\n",
    "'''\n",
    "def sentencesWith(filter_words=trait_keywords, df=sentsdf_top):\n",
    "    if isinstance(filter_words, str):\n",
    "        filter_regex = filter_words\n",
    "    elif isinstance(filter_words, list):\n",
    "        filter_regex = '|'.join(filter_words)\n",
    "    return df[df.Sentence.str.lower().str.contains(filter_regex)]\n",
    "\n",
    "'''\n",
    "Calculates the relevance of a given dataframe, based on matches in the trait keyword  list. \n",
    "Used to determine relevance of the entire article.\n",
    "args: df - The dataframe. By default, sentsdf.\n",
    "return: The numeric approximation of the relevance of the provided dataframe.\n",
    "'''\n",
    "def calculateRelevance(df = sentsdf_top.head()):\n",
    "    return sum(df.TKMC) / len(df) * 10.000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculateRelevance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = sentencesWith()\n",
    "df1.loc[df1.Cardinality > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_map = {\n",
    "    \"infectious\":\"infectious\", \n",
    "    \"contact\":\"contact\",\n",
    "    \"latency\":\"latency\",\n",
    "    \"latent\":\"latency\",\n",
    "    \"reproduction\":\"reproduction\"\n",
    "}\n",
    "stats_df = pd.DataFrame(index = set(dict_map.values()), columns=['Estimates','Citation','Rule'])\n",
    "stats_df.index.name = 'Parameter'\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "idx = None\n",
    "        \n",
    "\n",
    "def funnel_values(estimates, parameter, rule_name):\n",
    "    global stats_df\n",
    "    if parameter:\n",
    "        stats_df.at[parameter,'Estimates'] = estimates\n",
    "        stats_df.at[parameter,'Citation'] = idx\n",
    "        stats_df.at[parameter,'Rule'] = rule_name\n",
    "    elif idx not in list(stats_df.Citation) and\\\n",
    "        estimates not in list(stats_df.Estimates.loc[stats_df.Citation == idx]) :\n",
    "        stats_df.loc[len(stats_df)] = [estimates, idx, rule_name]\n",
    "\n",
    "def pm_map(matcher, doc, id, matches):\n",
    "    for match_id, start, end in matches:\n",
    "        string = str(doc[start:end])\n",
    "        split_span = string.split()\n",
    "        \n",
    "        avg = round(float(split_span[-3]),2)\n",
    "        moe = round(float(split_span[-1]),2)\n",
    "        \n",
    "        estimates = (avg-moe,avg+moe)\n",
    "        parameter = dict_map.get(split_span[0])\n",
    "        \n",
    "        funnel_values(estimates, parameter, \"pm_map\")\n",
    "\n",
    "        \n",
    "def bw_map(matcher, doc, id, matches):\n",
    "    for match_id, start, end in matches:\n",
    "        string = str(doc[start:end])\n",
    "        split_span = string.split('â')\n",
    "        \n",
    "        lower = round(float(split_span[0]),2)\n",
    "        upper = round(float(split_span[1]),2)\n",
    "        \n",
    "        estimates = (lower,upper)\n",
    "        parameter = dict_map.get(split_span[0])\n",
    "        \n",
    "        funnel_values(estimates, parameter, \"bw_map\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_rule = [{\"LIKE_NUM\":True}, {\"TEXT\":\"Â±\"}, {\"LIKE_NUM\":True}]\n",
    "bw_rule = [{\"LIKE_NUM\":True}, {\"TEXT\":\"â\"}, {\"LIKE_NUM\":True}]\n",
    "\n",
    "matcher.add(\"pm_rule\", pm_map, pm_rule)\n",
    "matcher.add(\"bw_rule\", bw_map, bw_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = pd.DataFrame(index = set(dict_map.values()), columns=['Estimates','Citation','Rule'])\n",
    "stats_df.index.name = 'Parameter'\n",
    "stats_df\n",
    "\n",
    "sents_filt = sentencesWith(specific_numerical_keywords)\n",
    "for idx in sents_filt.index:\n",
    "    sentence = sents_filt.Sentence[idx]\n",
    "    sentence = sentence.replace(\"â\",\" â \")\n",
    "    doc = nlp(sentence)\n",
    "    matches = matcher(doc)\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displaySurroundingText(207)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
